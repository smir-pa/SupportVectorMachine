# SupportVectorMachine

Набор данных:

В качестве исходного набора был выбран набор данных аутентификации (проверки подлинности) банкнот.

Информация о наборе:

Данные были получены из изображений подлинных и поддельных банкнот. Для оцифровки использовалась промышленная камера, обычно используемая для проверки печати. Конечные изображения имеют размер 400х400 пикселей. Были получены полутоновые изображения с разрешением около 660 точек на дюйм. Для извлечения из изображений атрибутов использовалось Вейвлет-преобразование.

Информация об атрибутах:
1. variance – дисперсия (Вейвлет-преобразование);
2. skewness – асимметрия (Вейвлет-преобразование);
3. curtosis – эксцесс (Вейвлет-преобразование);
4. entropy – энтропия изображения;
5. class – класс (0/1, подлинная или поддельная).

Еще немного о наборе:

Почему этот набор так хорош? Во-первых, он изначально подходит для решения задачи классификации. Здесь в наличии два класса и библиотека SKLearn справится с задачей (в отличие от мультиклассовой классификации, с которой возникают непонятные проблемы). Во-вторых, данные представлены в доступном для программы типе – real. Все данные в наборе определены (что очень важно) и описаны «без слов». Это удобно, так как нам потребуется распределить эти данные в массив типа float, и там не должно быть пустых ячеек, а также данных в строковом формате. В-третьих, у нас в наличии 1372 записи и 5 описывающих атрибутов. Это гибко, но главное – просто.

Библиотеки:

Для разработки SVM-классификатора использовалась библиотека pandas для загрузки данных в понятный для программы вид, sklearn для непосредственной работы с данными и matplotlib для графического представления.

Коротко о том, что происходит:

Итак, сначала подключаем необходимые библиотеки.

Затем нужно загрузить наш набор в программу. Данные загружаются из файла формата csv, а потом разделяются на feature и target соответственно по атрибуту Class.

После этого произведем нормализацию данных и создадим обучающие и тестовые выборки, а также настроим параметр регуляризации C, который в будущем можно будет изменить.

Далее остается только создать сам классификатор, задать нужные параметры, такие как ядро, параметр регуляризации, степень и др. и вывести оценку классификатора.

То же самое нужно проделать и с другими ядрами, но здесь будет только настройка оптимальных параметров для каждого классификатора.

Заранее будет отмечено, что сначала были использованы параметры по умолчанию (default) и лишь потом подбирались оптимальные для повышения оценки каждого классификатора.

Далее будут приведены результаты работы программы. Сначала мы увидим фрагмент наших загруженных данных: первые и последние пять записей, а также вид после нормализации.

Используя полученные данные, мы делаем вывод, что лучшими являются РБФ и полиномиальное ядро, поскольку оценка этих классификаторов показывает соответствующий результат. 

Линейное ядро находится достаточно близко к идеалу, так же как и сигмоидное.

Однако чтобы окончательно убедиться в преимуществе одного классификатора, построение гиперплоскости можно представить графически, рассмотрев два атрибута, например, Variance и Skewness. Так в зависимости от значений атрибутов элементы будут представлены на плоскости с последующим разделением на классы.

Итак, перед нами будет четыре графика по каждому использованному классификатору.

Программная реализация позволяет рассмотреть разделение на классы более подробно.

Сразу же становится наглядным очевидное преимущество полиномиального ядра и РБФ. Сравнивая их, легко убедиться, что полиномиальное ядро более гибко разделяет классы и существенно снижает значение ошибки. Хуже проявляет себя сигмоидное ядро. Так можно выставить их в следующем порядке: полиномиальное ядро, РБФ, линейное и сигмоидное.

Помимо этого, ради интереса можно использовать алгоритм машинного обучения t-SNE для визуализации. Он является техникой нелинейного снижения размерности, хорошо подходящей для вложения данных высокой размерности для визуализации в пространство низкой размерности (двух- или трехмерное). В частности, метод моделирует каждый объект высокой размерности двух- или трёхмерной точкой таким образом, что похожие объекты моделируются близко расположенными точками, а непохожие точки моделируются с большой вероятностью точками, далеко друг от друга отстоящими.

На двух классах выглядит не так эффектно, но когда их больше, результат впечатляет. Особенно эффектно выглядит создание модели в трехмерном пространстве, с которой можно взаимодействовать.
